1.
```python
import pandas as pd


data = pd.read_csv("C:/titanic.csv")
man = data.loc[(data["Sex"] == "male") & (data["Age"] >= 20) & (data["Age"] <= 40)]
woman = data.loc[(data["Sex"] == "female") & (data["Age"] >= 20) & (data["Age"] <= 40)]
man_num = len(man)
woman_num = len(woman)
print("{}:{}".format(man_num, woman_num))
```
2.
```python
import pandas as pd

data = pd.read_csv("C:/titanic.csv")
survived = data.loc[data["Survived"] == 1]
included = survived.loc[survived["Name"].str.contains("Mr|Mrs")]
result = included["Age"].mean()
print("{}".format(round(result, 2)))

```
3.
```python
import pandas as pd

data = pd.read_csv("C:/titanic.csv")
result = data.loc[(data["Fare"] > 40) & (data["Sex"] == "female") & (data["PassengerId"] % 2 == 1)]
print(len(result))

```
4.
```python
import pandas as pd

data = pd.read_csv("C:/titanic.csv")
tmp = [len(x.split(" ")) for x in data["Name"]]
ttmp = pd.Series(tmp)
data["Name"] = ttmp
result = data.loc[data["Name"] == data["Name"].median()]
rresult = result.loc[result["Sex"] == "male"]
print(len(rresult))
```
5.
```python
import pandas as pd
import xgboost as xgb
from sklearn.model_selection import train_test_split
pd.set_option('display.max_columns', None)  # or 1000
pd.set_option('display.max_rows', None)  # or 1000
pd.set_option('display.max_colwidth', None)  # or 199

data = pd.read_csv("C:/titanic.csv")

label = "Survived"

train_data = data.loc[:, data.columns != label]
label_data = data[label]
train_data = pd.get_dummies(train_data, columns=["Embarked", "Sex", "Cabin"])
train_data = train_data.drop(columns=["Name", "Ticket"])

train_x, test_x, train_y, test_y = train_test_split(train_data, label_data, train_size=0.9)

model = xgb.XGBClassifier().fit(train_x, train_y)
y_predict = model.predict(test_x)
result_df = test_x[["PassengerId"]]
result_df.loc[:,"predict"] = y_predict
result_df = result_df[result_df["PassengerId"] % 2 == 1]
result_df = result_df.reset_index()
print(result_df)
result_df.to_csv("C:/result/num5_result.csv")
```
6.
```python
import pandas as pd
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
import numpy as np

pd.set_option('display.max_columns', None)  # or 1000
pd.set_option('display.max_rows', None)  # or 1000
pd.set_option('display.max_colwidth', None)  # or 199

data = pd.read_csv("C:/titanic.csv")
# print(data.columns)
# print(data.isna().sum())
drop_column_list = ["Name", "Ticket", "Cabin", "Age"]
one_hot_column_list = ["Sex", "Embarked"]
data["Embarked"].fillna("S", inplace=True)

# drop
data.drop(columns=drop_column_list, inplace=True)
# one hot
data = pd.get_dummies(data, columns=one_hot_column_list)

x_data = data.loc[:, data.columns != "Survived"]
y_data = data[["Survived"]]
train_x, test_x, train_y, test_y = train_test_split(x_data, y_data, train_size=0.9)

model = XGBClassifier().fit(train_x, train_y)
predict_y = model.predict(test_x)

test_y = test_y.reset_index(drop=True)
diff_val = np.abs(predict_y - test_y["Survived"])

result_df = test_x[["PassengerId"]].reset_index(drop=True)
result_df["Diff"] = diff_val

result_df.to_csv("C:/result/num6_result.csv")

```
7.
```python
import pandas as pd

pd.set_option('display.max_columns', None)  # or 1000
pd.set_option('display.max_rows', None)  # or 1000
pd.set_option('display.max_colwidth', None)  # or 199

data = pd.read_csv("C:/titanic.csv")
# na check
# print(data.isna().sum())
# fill na, drop too many na
data["Age"].fillna(data["Age"].median(), inplace=True)
data["Embarked"].fillna(data["Embarked"].value_counts().index[0], inplace=True)
data.drop(columns="Cabin", inplace=True)
# value replace
# print(data["Embarked"].unique())
data["Embarked"].replace("C", 1, inplace=True)
data["Embarked"].replace("S", 2, inplace=True)
data["Embarked"].replace("Q", 3, inplace=True)
# print(data["Embarked"].unique())

data["order"] = data["Age"] + data["Pclass"]

data.sort_values(by="order", inplace=True)
result = data[:30]
print(result)
result.to_csv("C:/result/num7_result.csv")

```
