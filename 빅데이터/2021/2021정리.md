### 2021 출제 기준
- 분석 컨설팅(48)
    - 분석 시나리오 정의
    - 분석 방법론 구체화
- 데이터 탐색, 기초통계 분석(9)
    - 데이터 전처리 및 분석마트 구성
    - 데이터의 탐색
    - 기초통계분석
- 데이터 분석 모델 개발(23)
    - 모델의 이론적 이해(15)
        - ML
        - 텍스트 분석
    - 모델의 평가 및 활용(8)
        - 모델의 진단 및 평가
        - 모델의 적용 및 활용
- 신기술(15)
    - AWS, GCP 등 클라우드 환경에서 데이터 탐색 및 분석(ML Ops)
    - AI 이해, AutoML, Data AI, Explainable AI
- 데이터 엔지니어링(5)
    - 데이터 엔지니어링 교재 참고

### 분석 시나리오
0. 구체적 데이터셋 정의(어휘 정의 등-고객은 물품을 산 고객을 의미한다.)
1. 데이터 자체의 분석(독립성 검정, 종속변수 설정 등)
2. 모델의 선정(지도, 비지도 등), 그 이유(모델의 장점, 단점, 가정사항 등 서술 필요)
3. 데이터 전처리(na 값 처리, 표준화, 영향력 파악, 이상치 처리)
4. 모델 학습 방법(하이퍼 파라미터 세팅, 그리드 서치)
5. 모델 검정(cross validation 등)
6. 예측
7. 평가 및 시각화



- 통계분석
    - 데이터 요약 -> insight 도출
- 머신러닝
    - 모델 학습/추론 쉽게 반복 가능한 시스템 구축

- 대표적인 알고리즘
    - logistic regression model
        - 장점
            - 예측, 영향인자발굴, 최적화
        - 단점
            - 데이터가 많으면 느림
            - 이상치에 약함
            - 비현실적인 가정(타겟 이항분포, 오차항 독립, 다중공산성 부재)
            - 주관적인 판단 필요
            - 회귀계수 해석이 어려움
    - svm
        - 장점
            - 예측 정확도
            - 데이터 적어도 가능
            - 과적합에 강함
        - 단점
            - 파라미터가 많음(많은 테스트 필요)
            - 느림
            - 결과 해석이 거의 불가
            - 결과 시각화가 어려움
    - Random Forest(RF)
        - 장점
            - 과적합에 강함
            - 파라미터 설정을 대충해도 됨
        - 단점
            - 고차원, sparse 데이터에 부적합(차원에 비해 데이터 수가 적음)
            - 많은 메모리 사용
            - 느림
            - 해석이 어려움
    - XGBoost
        - 장점
            - 과적합에 강함
            - 속도가 빠름(GBM에 비해)
            - 다양한 loss function
            - 높은 정확도
            - 교차검증
        - 단점
            - 느림
            - 하이퍼 파라미터 튜닝에 오랜 시간이 걸림
            - 해석의 어려움
    - Light GBM
        - 장점
            - 빠른 속도
            - 적은 메모리
            - 매우 높은 정확도
        - 단점
            - 과적합
            - 해석의 어려움
    - neural net(NN)
        - 장점
            - 높은 정확도
            - 다양한 데이터형태에 적용 가능
            - 수학적으로 어려워도 가능
        - 단점
            - 과적합
            - 결과 해석의 어려움
            - 매우 느림
            - 데이터 품질, 하이퍼 파라미터의 영향을 많이 받음.
- 영향인자 발굴
    - feature importance
        - 장점
            - 앙상블 알고리즘에 대해서도 중요변수 추출 가능
            - 시각화 
        - 단점
            - 중요도 기준에 따라 결과 상이
            - 중요변수가 어떻게 영향을 주는지 알 수 없음
            - 편향적인 경향
    - decision tree
        - 장점
            - 빠른 최적 조건 도출
        - 단점
            - 변수를 고정하지 못함(사람이 중요하다고 판단한 변수)
        - 특정 조건에 맞는 terminal node로 조건을 유도하는 모델이 대부분
        - 현업과 논의하여 pruning 할 수도 있다.
        - 활용(운영)
            - 주기적으로 최근 데이터를 이용하여 영향인자 추출 하여 모델에서 얻어진 최적운영조건으로 조정. 
    - grid search
        - 장점
            - 사람이 조건값 확인 용이
        - 단점
            - 원하는 조건이 많으면 느림.
- 이상감지
    - PCA-Hotelling's T square
        - 특징
            - 양품 데이터만을 이용하여 정상 범위 선정
    - Autoencoder
        - 특징
            - 양품만을 사용
            - encode 후 decode 하는 방식
    - Isolation Forest
        - 단점
            - 고차원 데이터는 힘들다.
    - one class SVM
        - 특징
            - 정상 데이터만 사용
            - 초평면 경계 안에 있는 데이터만 정상.
    - 동적 시간 워핑
        - 특징
            - 시계열 데이터 비교
        - 장점
            - 유사도를 합리적으로 계산
            - 시점이 달라도 비교 가능
        - 단점
            - 완전히 반대가 되는 패턴도 유사한 것으로 추정
- 텍스트 분석
    - ㅔ
- 추천 시스템
    - Content Based filtering
        - 장점
            - 다른사용자의 영향을 받지 않음
            - 새로운 아이템 가능
            - 설명이 쉬움
        - 단점
            - 소리, 영상, 이미지는 힘듦
            - 새로운 사용자에게는 어려움
            - 너무 편향적 추천
    - collaboratibe filtering(협업 필터링)
        - 장점
            - 아이템의 특성에 의존 X
        - 단점
            - 많은 데이터 필요
            - 새롭거나 독특한 아이템 불가.
    - 연관성 분석
        - 장점
            - 결과 이해 쉬움
            - 계산 단순
        - 단점
            - 상품이 많아지면 느림
            - 너무 세분화된 품목 분석 불가.
- 모델(알고리즘) 검정(검증), 평가
    - regression
        - mean absolute err
            - 이해가 쉽다.
        - mean squared err
            - 큰 오차 더 크게, 작은 오차 더 작게
        - root mean squeare
            - mse 를 보정
        - mean absolute percentage err
            - 실제 데이터에서 오차가 어느 정도의 비율로 바생했는가
    - classification
        - confusion matrix
            - err rate
            - acc
            - sensitivity
            - specificity
            - precision
            - fp rate
            - f score
            - roc
    - validation
        - k fold cross validation
        - 사용하지 않은 data를 넣도 test한다.
- 모델 선정
    - 분류(classification)
        - 통계: 로지스틱, 판별 분석
        - 트리기반: decision tree, ㅊㅁㄳ
        - 최적화: svm
        - 기계학습
    - 예측(prediction)
        - 회귀분석, decision tree(의사결정트리), 인공신경망, 시계열 분석
    - 군집(clustering)
        - 불량 탐지, 고객 세분화, 그룹화, 분류
        - 계측적 군집: agglomerative, divisive
        - 비계층적 군집: kmeans, kmedoids, dbscan
        - 확률 기반 군집: 가우스
    - 연관규칙(association rule)
- ML Ops(Cloud, 클라우드)
    - 재현성
        - 균일한 결과
        - 모듈화
        - 추상화
    - 배치/정렬 자동화
    - Azure Cloud
        - 클라우드 컴퓨팅 환경 구축
            1. 사이트 접속
            2. 클러스터 생성(의사 분산모드, 교육용 가상머신 등 이용-클라우데아, 호튼웍스)
        - 클러스터 생성
            1. 클러스터 기본값 설정
            2. 메모리, cpu 크기 결정
            3. 비용 고려
            4. 스토리지, 네트워크 및 서브넷 설정값 확인
        - 가상머신 연결
            1. 공인주소 or 호스트 이름, ip 등을 이용한 연결
            2. 터미널 프로그램 등을 이요한 연결.
    - cloud 환경 모델 배포
        - 이미 환경이 세팅되어있다는 가정 하에, docker로 모델을 올리는 방법을 서술.






- 기타
    - 분산과 편차는 동시에 축소시킬 수 없다.
    - knn k 가 클수록 편차가 크다.
    - 선형의 독립변수 개수가 작을수록 분산이 크다.
    - bagging을 사용해도 모델의 오차를 줄일 수 없다.
    - ensemble
        - bagging
            - variance 감소
            - 과대적합 모형, 분산이 큰 모형에 적합
        - boosting: bias 감소
    - cross validation 은 검증용이지 실제 모델 개발용이 아님.
- 어휘 참고
    - 다중공산성
        - 독립변수들 사이에 강한 상관관계가 나타나는 문제

- 2020 기출
    - 